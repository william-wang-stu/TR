{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Higgs\n",
    "# edge_filepath = \"/remote-home/share/dmb_nas/wangzejian/TR_TNSE/higgs_twitter/higgs-social_network.edgelist\"\n",
    "# actionlog_filepath = \"/remote-home/share/dmb_nas/wangzejian/TR_TNSE/higgs_twitter/higgs_gen-actionlog-300.txt\"\n",
    "\n",
    "# Munmun\n",
    "# edge_filepath = \"/remote-home/share/dmb_nas/wangzejian/TR_TNSE/munmun_twitter_social/munmun_twitter_social.edges\"\n",
    "# actionlog_filepath = \"/remote-home/share/dmb_nas/wangzejian/TR_TNSE/munmun_twitter_social/munmun_gen-actionlog-300.txt\"\n",
    "\n",
    "# Virality2013\n",
    "edge_filepath = \"/remote-home/share/dmb_nas/wangzejian/TR_TNSE/virality2013_twitter/follower_gcc.anony.txt\"\n",
    "actionlog_filepath = \"/remote-home/share/dmb_nas/wangzejian/TR_TNSE/virality2013_twitter/timeline_tag.anony.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 21:52:22,510 Load ActionLog from File /remote-home/share/dmb_nas/wangzejian/TR_TNSE/virality2013_twitter/timeline_tag.anony.txt, ActionLog is Composed of 1345913 Diffusions\n",
      "2024-04-05 21:52:25,611 Sort ActionLog by Timestamp\n",
      "2024-04-05 21:52:29,815 Get 510795 Available Users\n",
      "2024-04-05 21:52:30,908 Split Train Diffusion 61070 and Test Diffusion 15268\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import logging\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# logging config\n",
    "def Beijing_TimeZone_Converter(sec, what):\n",
    "    beijing_time = datetime.datetime.now() + datetime.timedelta(hours=8)\n",
    "    return beijing_time.timetuple()\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(message)s') # include timestamp\n",
    "# logging.Formatter.converter = time.gmtime\n",
    "logging.Formatter.converter = Beijing_TimeZone_Converter\n",
    "\n",
    "def add_diffusion(diffusion_dict: dict, user, diffusion, timestamp):\n",
    "    if diffusion not in diffusion_dict:\n",
    "        diffusion_dict[diffusion] = []\n",
    "    diffusion_dict[diffusion].append((user, timestamp))\n",
    "\n",
    "def build_actionlog(actionlog_filepath: str, sep=','):\n",
    "    diffusion_dict = {}\n",
    "    with open(actionlog_filepath, \"r\") as f:\n",
    "        for line in f:\n",
    "            comps = line[:-1].split(',')\n",
    "            hashtag = comps[0]\n",
    "            for i in range(1, len(comps), 2):\n",
    "                timestamp, user_id = comps[i], comps[i+1]\n",
    "                add_diffusion(diffusion_dict, user_id, hashtag, int(timestamp))\n",
    "    # with open(actionlog_filepath, \"r\") as f:\n",
    "    #     for line in f:\n",
    "    #         user_id, hashtag, timestamp = line[:-1].split(sep)\n",
    "    #         add_diffusion(diffusion_dict, user_id, hashtag, int(timestamp))\n",
    "    logger.info(f\"Load ActionLog from File {actionlog_filepath}, ActionLog is Composed of {len(diffusion_dict)} Diffusions\")\n",
    "\n",
    "    # Sort by Timestamp\n",
    "    for diffusion in diffusion_dict:\n",
    "        diffusion_dict[diffusion] = sorted(diffusion_dict[diffusion], key = lambda item: int(item[1]))\n",
    "    logger.info(\"Sort ActionLog by Timestamp\")\n",
    "\n",
    "    return diffusion_dict\n",
    "\n",
    "def get_avail_users(diffusion_dict: dict):\n",
    "    user_s = set()\n",
    "    for key, items in diffusion_dict.items():\n",
    "        for item in items: user_s.add(item[0])\n",
    "    logger.info(f\"Get {len(user_s)} Available Users\")\n",
    "    return user_s\n",
    "\n",
    "# diffusion_dict = build_actionlog(actionlog_filepath, sep=',')\n",
    "diffusion_dict = build_actionlog(actionlog_filepath, sep=' ')\n",
    "user_s = get_avail_users(diffusion_dict)\n",
    "\n",
    "diffusion_dict = {k: v for k,v in diffusion_dict.items() if 10 <= len(v) <= 200}\n",
    "\n",
    "train_diffusion_dict, test_diffusion_dict = train_test_split(\n",
    "    list(diffusion_dict.keys()), test_size=0.2, random_state=42)\n",
    "\n",
    "train_diffusion_dict = {diffusion: diffusion_dict[diffusion] for diffusion in train_diffusion_dict}\n",
    "test_diffusion_dict = {diffusion: diffusion_dict[diffusion] for diffusion in test_diffusion_dict}\n",
    "logger.info(f\"Split Train Diffusion {len(train_diffusion_dict)} and Test Diffusion {len(test_diffusion_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "\n",
    "def read_network(filename):\n",
    "    G = nx.DiGraph()\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            if line[0] == '%':\n",
    "                continue\n",
    "            from_, to_ = line[:-1].split(',')[:2]\n",
    "            if from_ not in G.nodes():\n",
    "                G.add_node(\n",
    "                    from_,\n",
    "                    threshold = random.uniform(0,1),\n",
    "                    # influencesum = 0\n",
    "                )\n",
    "            if to_ not in G.nodes():\n",
    "                G.add_node(\n",
    "                    to_,\n",
    "                    threshold = random.uniform(0,1),\n",
    "                    # influencesum = 0\n",
    "                )\n",
    "            G.add_edge(from_, to_)\n",
    "\n",
    "    # compute sum of all its incoming node's out-degree for each node, \n",
    "    # out_degree_sum_map = {}\n",
    "    # for u in G.nodes():\n",
    "    #     sum = 0\n",
    "    #     for in_node, _ in G.in_edges(u):\n",
    "    #         sum += G.out_degree(in_node)\n",
    "    #     out_degree_sum_map[u] = sum\n",
    "    \n",
    "    # for (u, v) in G.edges:\n",
    "    #     G.edges[u, v][\"weight\"] = float(theta1 + theta2 * G.out_degree(u)) / out_degree_sum_map[v]\n",
    "    return G\n",
    "\n",
    "g = read_network(edge_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/61070 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 61070/61070 [02:48<00:00, 362.89it/s]\n",
      "2024-04-05 20:32:12,484 Total Training Time: 168.29227209091187\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "a_u = {}\n",
    "a_u2v = {}\n",
    "delta_t_u2v = {}\n",
    "credit_u2v = {}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for key, items in tqdm(train_diffusion_dict.items()):\n",
    "    # if len(items) < 10: continue\n",
    "\n",
    "    for i in range(0, len(items)):\n",
    "        user, ts = items[i][0], items[i][1]\n",
    "        if user not in a_u: a_u[user] = 0\n",
    "        a_u[user] += 1\n",
    "\n",
    "        for last_item in items[:i]:\n",
    "            last_user = last_item[0]\n",
    "            # if g[last_user][user] == 0: continue\n",
    "            if (last_user, user) not in a_u2v: a_u2v[(last_user, user)] = 0\n",
    "            a_u2v[(last_user, user)] += 1\n",
    "\n",
    "            if (last_user, user) not in delta_t_u2v: delta_t_u2v[(last_user, user)] = 0\n",
    "            delta_t_u2v[(last_user, user)] += ts - last_item[1]\n",
    "\n",
    "            if (last_user, user) not in credit_u2v: credit_u2v[(last_user, user)] = 0\n",
    "            credit_u2v[(last_user, user)] += 1/(i+1)\n",
    "\n",
    "logger.info(\"Total Training Time: {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/15268 [00:00<?, ?it/s]/tmp/ipykernel_7679/1830531291.py:52: RuntimeWarning: overflow encountered in exp\n",
      "  acc_p += p_u2v(pa, user, option=0) * np.exp(-safe_divide(ts-u2ts[pa], delta_t_u2v[(pa, user)]))\n",
      " 29%|██▉       | 4415/15268 [02:04<04:39, 38.85it/s]"
     ]
    }
   ],
   "source": [
    "### CT\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def safe_divide(a, b, eps=1e-6):\n",
    "    return a / (b + eps)\n",
    "\n",
    "def p_u2v(u, v, option=0):\n",
    "    try:\n",
    "        if option == 0: return safe_divide(a_u2v[(u, v)], a_u[u])\n",
    "        elif option == 1: return safe_divide(a_u2v[(u, v)], (a_u[u] + a_u[v] - a_u2v[(u, v)] - a_u2v[(v, u)]))\n",
    "        elif option == 2: return safe_divide(credit_u2v[(u, v)], a_u[u])\n",
    "        elif option == 3: return safe_divide(credit_u2v[(u,v)], (a_u[u] + a_u[v] - a_u2v[(u, v)] - a_u2v[(v, u)]))\n",
    "        else: raise Exception(\"Invalid Option\")\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for key, items in tqdm(test_diffusion_dict.items()):\n",
    "\n",
    "    y_trues = {}\n",
    "    y_preds = {}\n",
    "    ans_list = []\n",
    "    u2ts = {}\n",
    "\n",
    "    # us = set()\n",
    "    for user, ts in items:\n",
    "        if user not in y_preds:\n",
    "            y_preds[user] = 0\n",
    "            y_trues[user] = 2\n",
    "            ans_list.append((user, ts))\n",
    "            u2ts[user] = ts\n",
    "        else:\n",
    "            y_trues[user] = 1\n",
    "        \n",
    "        if user not in g.nodes: continue\n",
    "        for u in g.successors(user):\n",
    "            if u not in y_preds:\n",
    "                y_preds[u] = 0\n",
    "                y_trues[u] = 0\n",
    "                ans_list.append((u, -1))\n",
    "                u2ts[u] = -1\n",
    "\n",
    "    for user, ts in ans_list:\n",
    "        if user not in g.nodes: continue\n",
    "        acc_p = 0\n",
    "        for pa in g.predecessors(user):\n",
    "            if pa not in y_trues or pa not in u2ts: continue\n",
    "            if (pa, user) not in delta_t_u2v: continue\n",
    "            if y_trues[pa] != 1: continue\n",
    "            acc_p += p_u2v(pa, user, option=0) * np.exp(-safe_divide(ts-u2ts[pa], delta_t_u2v[(pa, user)]))\n",
    "        y_preds[user] = max(y_preds[user], acc_p)\n",
    "    \n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for user, ts in ans_list:\n",
    "        if user not in y_preds or not g.has_node(user): continue\n",
    "        try:\n",
    "            if y_trues[user] == 1 and y_preds[user] >= g.nodes[user][\"threshold\"]: tp += 1\n",
    "            elif y_trues[user] == 1 and y_preds[user] < g.nodes[user][\"threshold\"]: fn += 1\n",
    "            elif y_trues[user] == 0 and y_preds[user] >= g.nodes[user][\"threshold\"]: fp += 1\n",
    "            elif y_trues[user] == 0 and y_preds[user] < g.nodes[user][\"threshold\"]: tn += 1\n",
    "        except:\n",
    "            print(g.nodes[user])\n",
    "    \n",
    "    # logger.info(\"tag: {}, TP: {}, FP: {}, TN: {}, FN: {}\".format(key, tp, fp, tn, fn))\n",
    "    \n",
    "logger.info(\"Total Time: {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/60 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:24<00:00,  2.44it/s]\n",
      "2024-04-05 20:09:49,471 Total Time: 24.558175802230835\n"
     ]
    }
   ],
   "source": [
    "### DT\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def safe_divide(a, b, eps=1e-6):\n",
    "    return a / (b + eps)\n",
    "\n",
    "def p_u2v(u, v, option=0):\n",
    "    try:\n",
    "        if option == 0: return safe_divide(a_u2v[(u, v)], a_u[u])\n",
    "        elif option == 1: return safe_divide(a_u2v[(u, v)], (a_u[u] + a_u[v] - a_u2v[(u, v)] - a_u2v[(v, u)]))\n",
    "        elif option == 2: return safe_divide(credit_u2v[(u, v)], a_u[u])\n",
    "        elif option == 3: return safe_divide(credit_u2v[(u,v)], (a_u[u] + a_u[v] - a_u2v[(u, v)] - a_u2v[(v, u)]))\n",
    "        else: raise Exception(\"Invalid Option\")\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for key, items in tqdm(test_diffusion_dict.items()):\n",
    "\n",
    "    y_trues = {}\n",
    "    y_preds = {}\n",
    "    ans_list = []\n",
    "    u2ts = {}\n",
    "\n",
    "    # us = set()\n",
    "    for user, ts in items:\n",
    "        if user not in y_preds:\n",
    "            y_preds[user] = 0\n",
    "            y_trues[user] = 2\n",
    "            ans_list.append((user, ts))\n",
    "            u2ts[user] = ts\n",
    "        else:\n",
    "            y_trues[user] = 1\n",
    "        \n",
    "        if user not in g.nodes: continue\n",
    "        for u in g.successors(user):\n",
    "            if u not in y_preds:\n",
    "                y_preds[u] = 0\n",
    "                y_trues[u] = 0\n",
    "                # ans_list.append((u, -1))\n",
    "                u2ts[u] = -1\n",
    "            \n",
    "            acc_p = 0\n",
    "            for pa in g.predecessors(user):\n",
    "                if pa not in y_trues or pa not in u2ts: continue\n",
    "                if (pa, user) not in delta_t_u2v: continue\n",
    "                if y_trues[pa] != 1: continue\n",
    "                if ts - u2ts[pa] > delta_t_u2v[(pa, user)]: continue\n",
    "                acc_p += p_u2v(pa, user, option=0)\n",
    "            y_preds[user] = max(y_preds[user], acc_p)\n",
    "\n",
    "    for user, ts in ans_list:\n",
    "        if user not in g.nodes: continue\n",
    "        acc_p = 0\n",
    "        for pa in g.predecessors(user):\n",
    "            if pa not in y_trues or pa not in u2ts: continue\n",
    "            if (pa, user) not in delta_t_u2v: continue\n",
    "            if y_trues[pa] != 1: continue\n",
    "            acc_p += p_u2v(pa, user, option=0) * np.exp(-safe_divide(ts-u2ts[pa], delta_t_u2v[(pa, user)]))\n",
    "        y_preds[user] = max(y_preds[user], acc_p)\n",
    "    \n",
    "    tp, fp, tn, fn = 0, 0, 0, 0\n",
    "    for user, ts in ans_list:\n",
    "        if user not in y_preds or not g.has_node(user): continue\n",
    "        try:\n",
    "            if y_trues[user] == 1 and y_preds[user] >= g.nodes[user][\"threshold\"]: tp += 1\n",
    "            elif y_trues[user] == 1 and y_preds[user] < g.nodes[user][\"threshold\"]: fn += 1\n",
    "            elif y_trues[user] == 0 and y_preds[user] >= g.nodes[user][\"threshold\"]: fp += 1\n",
    "            elif y_trues[user] == 0 and y_preds[user] < g.nodes[user][\"threshold\"]: tn += 1\n",
    "        except:\n",
    "            print(g.nodes[user])\n",
    "    \n",
    "    # logger.info(\"tag: {}, TP: {}, FP: {}, TN: {}, FN: {}\".format(key, tp, fp, tn, fn))\n",
    "    \n",
    "logger.info(\"Total Time: {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GT\n",
    "\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Global Influence\n",
    "pr = nx.pagerank(g, alpha=0.85)\n",
    "\n",
    "# Social Influence\n",
    "a_u = {}\n",
    "a_u2v = {}\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for key, items in tqdm(train_diffusion_dict.items()):\n",
    "    # if len(items) < 10: continue\n",
    "\n",
    "    for i in range(0, len(items)):\n",
    "        user, ts = items[i][0], items[i][1]\n",
    "        if user not in a_u: a_u[user] = 0\n",
    "        a_u[user] += 1\n",
    "\n",
    "        for last_item in items[:i]:\n",
    "            last_user = last_item[0]\n",
    "            # if g[last_user][user] == 0: continue\n",
    "            if (last_user, user) not in a_u2v: a_u2v[(last_user, user)] = 0\n",
    "            a_u2v[(last_user, user)] += 1\n",
    "\n",
    "def safe_divide(a, b, eps=1e-6):\n",
    "    return a / (b + eps)\n",
    "\n",
    "def p_u2v(u, v):\n",
    "    try:\n",
    "        return safe_divide(a_u2v[(u, v)], a_u[u])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "# Preference Payoff\n",
    "\n",
    "# cascade->user sentences\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def get_ifidf_for_words(sentences):\n",
    "    tfidf_vectorizer = TfidfVectorizer(stop_words=\"english\")\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(sentences).todense()\n",
    "\n",
    "    feature_index = tfidf_matrix[0,:].nonzero()[1]\n",
    "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "    tfidf_scores = zip([feature_names[i] for i in feature_index], [tfidf_matrix[0, x] for x in feature_index])\n",
    "    return dict(tfidf_scores)\n",
    "\n",
    "cascade2users = [[elem[0] for elem in v] for _, v in train_diffusion_dict.items()]\n",
    "user_embs = get_ifidf_for_words(cascade2users)\n",
    "\n",
    "user2cascades = {}\n",
    "for key, items in train_diffusion_dict.items():\n",
    "    for item in items:\n",
    "        user = item[0]\n",
    "        if user not in user2cascades:\n",
    "            user2cascades[user] = []\n",
    "        user2cascades[user].append(key)\n",
    "user2cascades = list(user2cascades.values())\n",
    "cas_embs = get_ifidf_for_words(user2cascades)\n",
    "\n",
    "logger.info(\"Total Training Time: {}\".format(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for key, items in tqdm(test_diffusion_dict.items()):\n",
    "\n",
    "    active_users = set()\n",
    "    candidates_s = set()\n",
    "    for user, ts in items:\n",
    "        active_users.add(user)\n",
    "        if user not in g.nodes: continue\n",
    "        for u in g.successors(user):\n",
    "            candidates_s.add(u)\n",
    "    \n",
    "    for c in candidates_s:\n",
    "        soc_pos, soc_neg = 0, 0\n",
    "\n",
    "        for u in g.predecessors(c):\n",
    "            if u in active_users:\n",
    "                soc_pos += p_u2v(u, c) * pr[u]\n",
    "            else:\n",
    "                soc_neg += p_u2v(u, c) * pr[u]\n",
    "        \n",
    "        if key in cas_embs and c in user_embs:\n",
    "            soc_pos += cas_embs[key] * user_embs[c]\n",
    "\n",
    "        tp, fp, tn, fn = 0, 0, 0, 0\n",
    "        if c in active_users and soc_pos >= soc_neg: tp += 1\n",
    "        elif c in active_users and soc_pos < soc_neg: fn += 1\n",
    "        elif c not in active_users and soc_pos >= soc_neg: fp += 1\n",
    "        elif c not in active_users and soc_pos < soc_neg: tn += 1\n",
    "    \n",
    "    # logger.info(\"tag: {}, TP: {}, FP: {}, TN: {}, FN: {}\".format(key, tp, fp, tn, fn))\n",
    "    \n",
    "logger.info(\"Total Testing Time: {}\".format(time.time()-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyHeter-GAT-_-uOEIOh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
